{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "567ae234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import struct\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216dbcb0",
   "metadata": {},
   "source": [
    "I didn't have experience with using ubyte format of data, i tried to import directly from the keras datasets but it was too large to import so i used the help of internet resources and AI to figure out how to read these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98b538de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def load_images(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, 28, 28)\n",
    "    return data\n",
    "\n",
    "def load_labels(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f865f7",
   "metadata": {},
   "source": [
    "We will now create a class which inherits from the torch utils dataset, which is used to load the fashion mnist data in a way that PyTorch's DataLoader can work with. The init method initializes all the contents of the class, the len method gives the length of the labels, which is used by the Dataloader to find the length and the getitme method is used to retrieve a single sample when iterating through the DataLoader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c67d64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.fromarray(self.images[idx], mode='L')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d591fa8",
   "metadata": {},
   "source": [
    "Now to convert our 1 channel grayscale images which are in 24 x 24, into images which fit with our Resnet model which accepts 3 channel data, so we convert the images into 3 channel RGB and 224 x 224. We are also normalizing the images so that their mean is 0 and standard dev is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63fee551",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c35e3a",
   "metadata": {},
   "source": [
    "Loading all the data from ubyte files and using the dataloaders to load the data into batches and shuffling them. Alos applying the transforms that we defined in the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d1be537",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_images(\"train-images-idx3-ubyte\")\n",
    "train_labels = load_labels(\"train-labels-idx1-ubyte\")\n",
    "test_images = load_images(\"t10k-images-idx3-ubyte\")\n",
    "test_labels = load_labels(\"t10k-labels-idx1-ubyte\")\n",
    "\n",
    "train_dataset = FashionMNISTDataset(train_images, train_labels, transform=transform_train)\n",
    "val_dataset = FashionMNISTDataset(test_images, test_labels, transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba899f34",
   "metadata": {},
   "source": [
    "Importing the pretrained ResNet model and freezing the layers of the resnet backbone by applying requires grad to false. Then creating our top layer on top of the resnet layers, We apply a linear model with 256 neurons, then applying the Relu function which simply applies all negative values to 0 and positive values to the same value. At the end one more neural layer which collects from 256 neuron layer to 10 output neurons which classify the data into finally 10 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "861b9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da92d9",
   "metadata": {},
   "source": [
    "Now we unfreeze the lower levels of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d83f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805081e",
   "metadata": {},
   "source": [
    "Now we will define the optimizer which will be Adam and i ma using a learning rate of 0.0001, i tried to reduce it but the accuracy just decreased and i found this to be the best lr i could get to reduce overfitting. After that we define the training loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a80a4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "def train_model(model, epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0.0, 0, 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(f\"  Batch {i+1}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
    "        acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Train Acc: {acc:.2f}%\")\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8500123",
   "metadata": {},
   "source": [
    "Now to evaluate the model we use the validationg set to get the validation accuracy, we have changed the name of the test dataset to validation loader and used it to test the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "544dcbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "  Batch 1/938 | Loss: 2.3265\n",
      "  Batch 51/938 | Loss: 1.8261\n",
      "  Batch 101/938 | Loss: 1.4752\n",
      "  Batch 151/938 | Loss: 1.0733\n",
      "  Batch 201/938 | Loss: 1.0699\n",
      "  Batch 251/938 | Loss: 0.9255\n",
      "  Batch 301/938 | Loss: 0.8745\n",
      "  Batch 351/938 | Loss: 0.8164\n",
      "  Batch 401/938 | Loss: 0.7938\n",
      "  Batch 451/938 | Loss: 0.9775\n",
      "  Batch 501/938 | Loss: 0.5607\n",
      "  Batch 551/938 | Loss: 0.8053\n",
      "  Batch 601/938 | Loss: 0.8526\n",
      "  Batch 651/938 | Loss: 0.6568\n",
      "  Batch 701/938 | Loss: 0.8315\n",
      "  Batch 751/938 | Loss: 0.7686\n",
      "  Batch 801/938 | Loss: 0.6961\n",
      "  Batch 851/938 | Loss: 0.6733\n",
      "  Batch 901/938 | Loss: 0.5725\n",
      "Epoch [1/3], Loss: 858.6535, Train Acc: 71.73%\n",
      "  Batch 1/938 | Loss: 0.6248\n",
      "  Batch 51/938 | Loss: 0.4180\n",
      "  Batch 101/938 | Loss: 0.5218\n",
      "  Batch 151/938 | Loss: 0.6627\n",
      "  Batch 201/938 | Loss: 0.6461\n",
      "  Batch 251/938 | Loss: 0.5982\n",
      "  Batch 301/938 | Loss: 0.4888\n",
      "  Batch 351/938 | Loss: 0.7905\n",
      "  Batch 401/938 | Loss: 0.5458\n",
      "  Batch 451/938 | Loss: 0.5082\n",
      "  Batch 501/938 | Loss: 0.5360\n",
      "  Batch 551/938 | Loss: 0.4365\n",
      "  Batch 601/938 | Loss: 0.6492\n",
      "  Batch 651/938 | Loss: 0.5458\n",
      "  Batch 701/938 | Loss: 0.5744\n",
      "  Batch 751/938 | Loss: 0.6043\n",
      "  Batch 801/938 | Loss: 0.6043\n",
      "  Batch 851/938 | Loss: 0.5295\n",
      "  Batch 901/938 | Loss: 0.6219\n",
      "Epoch [2/3], Loss: 542.6152, Train Acc: 79.83%\n",
      "  Batch 1/938 | Loss: 0.7066\n",
      "  Batch 51/938 | Loss: 0.5163\n",
      "  Batch 101/938 | Loss: 0.5251\n",
      "  Batch 151/938 | Loss: 0.4580\n",
      "  Batch 201/938 | Loss: 0.5891\n",
      "  Batch 251/938 | Loss: 0.3854\n",
      "  Batch 301/938 | Loss: 0.5413\n",
      "  Batch 351/938 | Loss: 0.4350\n",
      "  Batch 401/938 | Loss: 0.6105\n",
      "  Batch 451/938 | Loss: 0.4194\n",
      "  Batch 501/938 | Loss: 0.6787\n",
      "  Batch 551/938 | Loss: 0.4871\n",
      "  Batch 601/938 | Loss: 0.4481\n",
      "  Batch 651/938 | Loss: 0.4821\n",
      "  Batch 701/938 | Loss: 0.5054\n",
      "  Batch 751/938 | Loss: 0.4270\n",
      "  Batch 801/938 | Loss: 0.4130\n",
      "  Batch 851/938 | Loss: 0.5465\n",
      "  Batch 901/938 | Loss: 0.3742\n",
      "Epoch [3/3], Loss: 485.1985, Train Acc: 81.97%\n",
      "Validation Accuracy: 83.45%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.2f}%\")\n",
    "\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "train_model(model, epochs=3)\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3cc7c2",
   "metadata": {},
   "source": [
    "Results : \n",
    "\n",
    "Accuracy - 83.5%\n",
    "Loss - 485.20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
