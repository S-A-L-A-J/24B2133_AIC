AI Hackathon Preparation Timeline
-

After studying a few famous hackathons going on currently on the internet, mainly on Devpost and Machine Hack, i found out the general type of Hackathons for AI. These are the key points -
For our case, i am considering a team hackathon so each team is either allowed to come up with their own problem statement or choose one of the few pre-defined ones. The hackathon may last for 24 hours or a few days,
but mostly AI hackathons last for more that 24 hours atleast. There is a timeline defined and for some of the hackathons i found on Devpost, the submission time was around a month. 

So for our case i am considering choosing our own problem statement as mentioned in the question and a time period of around a week for the hackathon to last. Based on this information the following is my preparation plan :

Firstly, we must plan what we will be doing and how, this will build a solid foundation and create ease in the further process. Taking around a week for problem statement ideation and proof-checking its validity and originality. We must come up with a problem statement whose idea is quite original
and has not been done already or atleast a different adaptation of already existing ideas. After short-lisiting some enthusiatic ideas, we should eliminate some while being practical about the timeline of the hackathon, 
our computational power resources, becuase some ideas might be too good to be true at our level. So while being realistic choose a few ideas from those, then we must check whether they are easily implementable as well as 
how easy or difficult it will be to collect data for the model to train, some problems might need us to take data in real-world scenarios, so that would be really impractical. Also we must consider, are there suitable
algorithms existing that would simplify our problem, if yes then which kind of machine learning algorithm should be employed to complete the task. Using basic algorithms like Regression, CNNs, etc. can provide us with a proof of concept that this is doable. Considering all the above
factors, we can choose one problem statement which fits all the parameters correctly.

Once we have brainstormed and selected a solid problem statement, we must focus on getting the food for the model, i.e. data. The team must focus on how to get the data for the model and what pre-processing techniques
we will use. Since we already thought about the accesibility of the data during the brain-storming, there must be some basic data available for one part of the team to work on to find the preproccesing techniques while the
other part of the team works to find more datasets for the model. Searching different API, public datasets, and sometimes we may need to take our own samples of data if they might not be available. Trying various preprocessing 
techniques allows us to identify which things in the data are not for our use, and may mislead the model. To identify this, using basic models to categorize the data and find anomalies in the data. 

After collecting a good amount of data, it is necessary to visualise the data and spend time with it to get a feel of it. What are the trends in the data, what are the most common and least common values in the data, 
make sure that the data is not biased and we have an even distribution of all classes of data, understanding correlations of certain features. During this time, we will also achieve a sense of what parameters and features 
of the data are of our use and which should be discarded because obviously there will be some part of the data that is rubbish for us. 

Now comes the most important part, once we have optimized the data while keeping our problem statement in mind, we should now move to selecting which model and way of AI we should use. Since we did some groundwork already
during the ideation process, we know which kinds of basic functions our model should have like Regression or Neural nets. While keeping our final goal in mind, explore higher versions of these algorithms and understand
already existing models what we might import and fine tune the model to meet our needs. There are various kinds of high level models out there which may fit our use case, if the competiton allows it, then it is good to have
a sense of the different models that we might use.
