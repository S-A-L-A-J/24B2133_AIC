AI Hackathon Preparation Timeline
-

After studying a few famous hackathons going on currently on the internet, mainly on Devpost and Machine Hack, i found out the general type of Hackathons for AI. These are the key points -
For our case, i am considering a team hackathon so each team is either allowed to come up with their own problem statement or choose one of the few pre-defined ones. The hackathon may last for 24 hours or a few days,
but mostly AI hackathons last for more that 24 hours atleast. There is a timeline defined and for some of the hackathons i found on Devpost, the submission time was around a month. 

So for our case i am considering choosing our own problem statement as mentioned in the question and a time period of around a week for the hackathon to last. Based on this information the following is my preparation plan :

Firstly, we must plan what we will be doing and how, this will build a solid foundation and create ease in the further process. Taking around a week for problem statement ideation and proof-checking its validity and originality. We must come up with a problem statement whose idea is quite original
and has not been done already or atleast a different adaptation of already existing ideas. After short-lisiting some enthusiatic ideas, we should eliminate some while being practical about the timeline of the hackathon, 
our computational power resources, becuase some ideas might be too good to be true at our level. So while being realistic choose a few ideas from those, then we must check whether they are easily implementable as well as 
how easy or difficult it will be to collect data for the model to train, some problems might need us to take data in real-world scenarios, so that would be really impractical. Also we must consider, are there suitable
algorithms existing that would simplify our problem, if yes then which kind of machine learning algorithm should be employed to complete the task. Using basic algorithms like Regression, CNNs, etc. can provide us with a proof of concept that this is doable. Considering all the above
factors, we can choose one problem statement which fits all the parameters correctly.

Once we have brainstormed and selected a solid problem statement, we must focus on getting the food for the model, i.e. data. The team must focus on how to get the data for the model and what pre-processing techniques
we will use. Since we already thought about the accesibility of the data during the brain-storming, there must be some basic data available for one part of the team to work on to find the preproccesing techniques while the
other part of the team works to find more datasets for the model. Searching different API, public datasets, and sometimes we may need to take our own samples of data if they might not be available. Trying various preprocessing 
techniques allows us to identify which things in the data are not for our use, and may mislead the model. To identify this, using basic models to categorize the data and find anomalies in the data. 

After collecting a good amount of data, it is necessary to visualise the data and spend time with it to get a feel of it. What are the trends in the data, what are the most common and least common values in the data, 
make sure that the data is not biased and we have an even distribution of all classes of data, understanding correlations of certain features. During this time, we will also achieve a sense of what parameters and features 
of the data are of our use and which should be discarded because obviously there will be some part of the data that is rubbish for us. 

Now comes the most important part, once we have optimized the data while keeping our problem statement in mind, we should now move to selecting which model and way of AI we should use. Since we did some groundwork already
during the ideation process, we know which kinds of basic functions our model should have like Regression or Neural nets. While keeping our final goal in mind, explore higher versions of these algorithms and understand
already existing models what we might import and fine tune the model to meet our needs. There are various kinds of high level models out there which may fit our use case, if the competiton allows it, then it is good to have a sense of the different models that we might use.

Selecting the model is not it, we also must select the training process and the parameters of the model. The parameters of the model are very crucial, they many times determine the training time for the model. We must very carefully choose the training process and the requirements of our computing, i.e. the graphics card and how much maximum power we can get. This is necessary because let's say the hackathon is for a week, so we will obviously tweak the hyperparameters to get the best possible results, if the training time per each run is around a day then we cannot experiment a lot, so the minimum time the model takes to train is better for the maximum accuracy we can get. Choosing some thresholds for some model parameters may speed up the training process rapidly, so it is a good idea to keep a note of possible parameters we can tweak or add to make the model faster while training. 

Once we have laid a foundation, and conducted a good research of all the above part and the hackathon is near, we move to the team phase and designating different roles that will be upheld by each team member. Key roles that we must take into account are : 
Machine Learning and Algorithm Desgning Engineers, Data Processing and Searching engineers, Metrics and Evaluation, Business or Pitching team to present the ML model. 

There are always some things that don’t go according to plan, so it’s better to be prepared beforehand. One of the biggest problems we might face is that the dataset we chose turns out to be very poor in quality, or worse, not available as expected. To avoid this, we should always have some backup datasets or at least a plan to generate synthetic data or do augmentation. Another issue can be that our model is not performing well—either it overfits or completely misses the pattern. In such cases, it’s good to have a few simple models ready just to make sure the concept works. Time is another thing that can mess everything up. If we don’t track our progress well, we might get stuck tweaking the model when we should be preparing for the final presentation. That’s why we should divide the work early and maybe set daily targets to keep things in check. Also, we never know when a team member might get caught up with something else, so it’s important that the work is properly shared and documented. Everyone should know a bit of what the others are doing so the project doesn’t halt if one person is unavailable. Lastly, we should aim to finish the whole thing at least half a day before the final deadline, just in case something breaks or doesn’t work at the last moment. A little bit of buffer time can save a lot of stress.
